{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMY815HOs6bZzwXCLX3K4C/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anand-therattil/machine_learning/blob/main/pytorch_deeplearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have created this colab notebook to learn the deep learning using [PyTorch by Partrick Loeber](https://youtu.be/exaWOE8jvy8?si=AGBT7Nr61MBT9nhW)\n",
        "\n",
        "Installation of pytorch in google colab can be done using ``` !pip install torch ```\n",
        "\n",
        "To check if the pytorch is installed run this if there are no Error then the pytorch is installed successfully\n",
        "Else go the https://pytorch.org/"
      ],
      "metadata": {
        "id": "9L9WlOaNLfPh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nEJuzoTs7HiH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69ffffdb-ca1c-4d03-cdb1-fd640682a4a5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.is_available()  # to check if cuda/ GPU is available if False then cuda is not present True if present"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basic Defining"
      ],
      "metadata": {
        "id": "r3XIVPEm0wf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random tensor\n",
        "# torch.rand(dimension,dtype )\n",
        "x = torch.rand(3)\n",
        "print(x)\n",
        "\n",
        "# Empty tensor\n",
        "# torch.empty(dimension,dtype)\n",
        "# Here empty tensor means there will be a value however it will in the value ranged in e^-10 (depends on the system )\n",
        "x = torch.empty(1,2)\n",
        "print(x)\n",
        "\n",
        "# Ones tensor\n",
        "# torch.ones(dimension,dtype)\n",
        "x = torch.ones(1,4)\n",
        "print(x)\n",
        "\n",
        "# to check the size of a tensor we can use the x.size()\n",
        "print(x.size())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-budbU1_Af9h",
        "outputId": "61ee6abf-bd5d-49ef-f427-3b70279094fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.7581, 0.4986, 0.0113])\n",
            "tensor([[0., 0.]])\n",
            "tensor([[1., 1., 1., 1.]])\n",
            "torch.Size([1, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basic Operations\n",
        "1. I have show for addition similar can be applicable for the\n",
        "subtraction, multiplication, division and modulus.\n",
        "2. Reshaping of the tensor using the ``` view()```"
      ],
      "metadata": {
        "id": "RVs_vJev03Yr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(2,2)\n",
        "y = torch.ones(2,2)\n",
        "\n",
        "print(x+y)\n",
        "# Or\n",
        "print(torch.add(x,y))\n",
        "\n",
        "\n",
        "# Inplace Operation\n",
        "y.add_(x) # Inplace addition\n",
        "print(y)\n",
        "\n",
        "# Reshaping of the tensor vector\n",
        "# Keep in mind that while reshaping the present dimension should match with the current dimension\n",
        "# However if the dimension is set as -1 the object automotically defines it\n",
        "print(y.view(4,1))\n",
        "print(y.view(-1,4))\n",
        "print(y.view(4,-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbXDNXRT00OF",
        "outputId": "50320985-e9f1-42cb-aacb-85407119731d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.9123, 1.2155],\n",
            "        [1.7478, 1.0974]])\n",
            "tensor([[1.9123, 1.2155],\n",
            "        [1.7478, 1.0974]])\n",
            "tensor([[1.9123, 1.2155],\n",
            "        [1.7478, 1.0974]])\n",
            "tensor([[1.9123],\n",
            "        [1.2155],\n",
            "        [1.7478],\n",
            "        [1.0974]])\n",
            "tensor([[1.9123, 1.2155, 1.7478, 1.0974]])\n",
            "tensor([[1.9123],\n",
            "        [1.2155],\n",
            "        [1.7478],\n",
            "        [1.0974]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conversion to Numpy and vice versa"
      ],
      "metadata": {
        "id": "rpw8nMxJ64-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "a = torch.rand(3,3)\n",
        "b = a.numpy()\n",
        "print(type(a))\n",
        "print(type(b))\n",
        "# However in this approach the if the value of a changes the value of b changes\n",
        "\n",
        "a = torch.rand(3,3)\n",
        "b = torch.from_numpy(a.numpy())\n",
        "print(type(a))\n",
        "print(type(b))\n",
        "\n",
        "# In this the one the tensor are the cpu tensor however if the tensor is on the GPU then need to convert to cpu first then can be used for the for the numpy\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "a.to(device)\n",
        "z =a + b\n",
        "z.to(\"cpu\") # To make it back  to normal tensor\n",
        "z = torch.from_numpy(z.numpy())\n",
        "z = z.numpy()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPX13K7S1loa",
        "outputId": "51241566-353a-485d-da2c-e1fbbb15d515"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'torch.Tensor'>\n",
            "<class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculation of Gradient through Backwards Propogation"
      ],
      "metadata": {
        "id": "OjsjV6YUgBcG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(3,requires_grad =True)\n",
        "print(x)\n",
        "\n",
        "y = x + 2\n",
        "print(y)\n",
        "\n",
        "z = y*y*2\n",
        "print(z)\n",
        "# z = z.sum()\n",
        "z.backward(torch.tensor([1,1,3]))\n",
        "\n",
        "print(x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TW7Kd8KzgFnl",
        "outputId": "462a2761-d9c6-464f-ac61-8e7cc63dd2ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.1230, 0.5288, 0.7583], requires_grad=True)\n",
            "tensor([2.1230, 2.5288, 2.7583], grad_fn=<AddBackward0>)\n",
            "tensor([ 9.0140, 12.7896, 15.2160], grad_fn=<MulBackward0>)\n",
            "tensor([ 8.4919, 10.1152, 33.0992])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(3,requires_grad =True)\n",
        "print(x)\n",
        "\n",
        "y = x.detach() + 2\n",
        "print(y)\n",
        "\n",
        "z = y*y*2\n",
        "print(z)\n",
        "# z = z.sum()\n",
        "# z.backward(torch.tensor([1,1,3]))\n",
        "\n",
        "print(x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YhTVMyywHDx",
        "outputId": "72905348-1ba3-41d4-bb33-de3c65d80623"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.8013, 0.3743, 0.1006], requires_grad=True)\n",
            "tensor([2.8013, 2.3743, 2.1006])\n",
            "tensor([15.6944, 11.2744,  8.8247])\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torch.ones(4,requires_grad=True)\n",
        "print(weights)\n",
        "\n",
        "for i in range(3):\n",
        "  model_output = (weights*3).sum()\n",
        "  model_output.backward()\n",
        "  print(weights.grad)\n",
        "  weights.grad.zero_()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IBQ1CT7x9QB",
        "outputId": "fc9df491-ed19-4d6d-babf-429202e100e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1.], requires_grad=True)\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torch.ones(4,requires_grad=True)\n",
        "print(weights)\n",
        "\n",
        "for i in range(3):\n",
        "  model_output = (weights*3).sum()\n",
        "  model_output.backward()\n",
        "  print(weights.grad)\n",
        "  weights.grad.zero_()"
      ],
      "metadata": {
        "id": "yHfrN4RlzJ-y",
        "outputId": "b15f5d24-7220-43c9-e00e-944d849bcb35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1.], requires_grad=True)\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n",
            "tensor([3., 3., 3., 3.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "X = torch.tensor([[1],[2],[3],[4]], dtype= torch.float32)\n",
        "Y = torch.tensor([[2],[4],[6],[8]], dtype= torch.float32)\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "print(n_samples, n_features)\n",
        "input_size, output_size  = n_features, n_features\n",
        "model = nn.Linear(input_size,output_size)\n",
        "\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "loss = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr= learning_rate)\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  y_pred = model(X)\n",
        "\n",
        "  l = loss(Y, y_pred)\n",
        "\n",
        "  l.backward()\n",
        "\n",
        "  optimizer.step()\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if(epoch %10 ==0):\n",
        "    [w,b] = model.parameters()\n",
        "    print('epoch: '+str(epoch+1)+ \" w:\" +str(w)+\" loss: \"+str(l))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "d2zwq5t2tE34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb67b3cb-5151-4bae-fd1d-3f8e13c0926a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4 1\n",
            "epoch: 1 w:Parameter containing:\n",
            "tensor([[0.4791]], requires_grad=True) loss: tensor(28.2055, grad_fn=<MseLossBackward0>)\n",
            "epoch: 11 w:Parameter containing:\n",
            "tensor([[1.6973]], requires_grad=True) loss: tensor(0.7366, grad_fn=<MseLossBackward0>)\n",
            "epoch: 21 w:Parameter containing:\n",
            "tensor([[1.8950]], requires_grad=True) loss: tensor(0.0255, grad_fn=<MseLossBackward0>)\n",
            "epoch: 31 w:Parameter containing:\n",
            "tensor([[1.9285]], requires_grad=True) loss: tensor(0.0067, grad_fn=<MseLossBackward0>)\n",
            "epoch: 41 w:Parameter containing:\n",
            "tensor([[1.9355]], requires_grad=True) loss: tensor(0.0059, grad_fn=<MseLossBackward0>)\n",
            "epoch: 51 w:Parameter containing:\n",
            "tensor([[1.9381]], requires_grad=True) loss: tensor(0.0055, grad_fn=<MseLossBackward0>)\n",
            "epoch: 61 w:Parameter containing:\n",
            "tensor([[1.9401]], requires_grad=True) loss: tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
            "epoch: 71 w:Parameter containing:\n",
            "tensor([[1.9419]], requires_grad=True) loss: tensor(0.0049, grad_fn=<MseLossBackward0>)\n",
            "epoch: 81 w:Parameter containing:\n",
            "tensor([[1.9436]], requires_grad=True) loss: tensor(0.0046, grad_fn=<MseLossBackward0>)\n",
            "epoch: 91 w:Parameter containing:\n",
            "tensor([[1.9453]], requires_grad=True) loss: tensor(0.0043, grad_fn=<MseLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "X = torch.tensor([[1],[2],[3],[4]], dtype= torch.float32)\n",
        "Y = torch.tensor([[2],[4],[6],[8]], dtype= torch.float32)\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "print(n_samples, n_features)\n",
        "input_size, output_size  = n_features, n_features\n",
        "\n",
        "class LinearRegression(nn.Module):\n",
        "  def __init__(self, input_dim, output_dim):\n",
        "    super(LinearRegression, self).__init__()\n",
        "    self.lin = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.lin(x)\n",
        "\n",
        "model = LinearRegression(input_size, output_size)\n",
        "\n",
        "learning_rate = 0.01\n",
        "n_iters = 100\n",
        "loss = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr= learning_rate)\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  y_pred = model(X)\n",
        "\n",
        "  l = loss(Y, y_pred)\n",
        "\n",
        "  l.backward()\n",
        "\n",
        "  optimizer.step()\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if(epoch %10 ==0):\n",
        "    [w,b] = model.parameters()\n",
        "    print('epoch: '+str(epoch+1)+ \" w:\" +str(w)+\" loss: \"+str(l))\n"
      ],
      "metadata": {
        "id": "uPV3i31XQRpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear Regression\n",
        "# Making the model\n",
        "# Defining the Loss function, Optimizer\n",
        "# Plotting of Data\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy   as np\n",
        "from   sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "X_numpy, y_numpy = datasets.make_regression(n_samples=100,n_features=1, noise=30, random_state=2)\n",
        "\n",
        "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
        "y = torch.from_numpy(y_numpy.astype(np.float32))\n",
        "y = y.view(y.shape[0], 1)  # This step is important as it converts the data in thr ([[a],[b]]) format\n",
        "\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "input_size = n_features\n",
        "output_size = 1\n",
        "print(n_features)\n",
        "model = nn.Linear(input_size, output_size)\n",
        "\n",
        "learning_rate = 0.01\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "  y_pred = model(X)\n",
        "  loss = criterion(y_pred,y)\n",
        "\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if(epoch%10==0):\n",
        "    print(loss)\n",
        "\n",
        "\n",
        "y_pred = model(X).detach().numpy()\n",
        "plt.plot(X_numpy,y_numpy, 'ro')\n",
        "plt.plot(X_numpy,y_pred, 'b')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "GDu4OPanBMnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy   as np\n",
        "from   sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "total_data = datasets.load_breast_cancer()\n",
        "data, target = total_data.data, total_data.target\n",
        "target = np.array(target)\n",
        "target = target.reshape(target.shape[0], 1)\n",
        "n_samples, n_features = data.shape\n",
        "print(target.shape)\n",
        "print(n_samples, n_features)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data,target, test_size = 0.2, random_state=2)\n",
        "\n",
        "Scaler = StandardScaler()\n",
        "X_train = Scaler.fit_transform(X_train)\n",
        "X_test = Scaler.fit_transform(X_test)\n",
        "\n",
        "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
        "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
        "\n",
        "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
        "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "class Logistic_Regression(nn.Module):\n",
        "  def __init__(self, n_features):\n",
        "    super(Logistic_Regression, self).__init__()\n",
        "    self.Linear = nn.Linear(n_features, 1)\n",
        "\n",
        "  def forward(self,x):\n",
        "    y_predicted = torch.sigmoid(self.Linear(x))\n",
        "    return y_predicted\n",
        "\n",
        "model = Logistic_Regression(n_features)\n",
        "\n",
        "learning_rate = 0.01\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "  y_pred = model(X_train)\n",
        "  loss = criterion(y_pred,y_train)\n",
        "\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if(epoch%10==0):\n",
        "    print(loss)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsBXLHCpBYm6",
        "outputId": "4a2e0a19-d921-4f76-9418-a85fceb554bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(569, 1)\n",
            "569 30\n",
            "torch.Size([455, 30])\n",
            "torch.Size([455, 1])\n",
            "torch.Size([114, 30])\n",
            "torch.Size([114, 1])\n",
            "tensor(0.9592, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.6938, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.5455, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.4592, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.4035, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.3642, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.3346, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.3114, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.2926, grad_fn=<BinaryCrossEntropyBackward0>)\n",
            "tensor(0.2770, grad_fn=<BinaryCrossEntropyBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  y_pred = model(X_test)\n",
        "  y_pred = y_pred.round()\n",
        "\n",
        "  acc = y_pred.eq(y_test).sum()/float(y_test.shape[0]) *100\n",
        "  print(acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DHnpdjoNU0Y",
        "outputId": "ff602b82-8e22-49b8-887d-23fb22e1e378"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(95.6140)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tensorboard --logdir=runs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrwMVOIZAQOi",
        "outputId": "d9a51c97-1738-4fe5-cd33-c0ff96e0dc80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-05-07 17:15:39.120132: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-05-07 17:15:39.120207: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-05-07 17:15:39.121746: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-05-07 17:15:39.131192: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-05-07 17:15:40.698645: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\n",
            "NOTE: Using experimental fast data loading logic. To disable, pass\n",
            "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
            "    https://github.com/tensorflow/tensorboard/issues/4784\n",
            "\n",
            "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
            "TensorBoard 2.15.2 at http://localhost:6006/ (Press CTRL+C to quit)\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "input_size = 784 # 28X28 size\n",
        "hidden_size = 100\n",
        "num_classes = 10\n",
        "num_epochs = 2\n",
        "batch_size = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                           train=True,\n",
        "                                           download=True,\n",
        "                                           transform=transforms.ToTensor())\n",
        "\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                           train=False,\n",
        "                                           download=True,\n",
        "                                           transform=transforms.ToTensor())\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset= train_dataset,\n",
        "                                       batch_size=batch_size,\n",
        "                                       shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset= test_dataset,\n",
        "                                       batch_size=batch_size,\n",
        "                                       shuffle=True)\n",
        "\n",
        "examples= iter(train_loader)\n",
        "samples, labels = examples.__next__()\n",
        "print(samples.shape, labels.shape)\n",
        "\n",
        "\n",
        "class NeuralNet(nn.Module):\n",
        "  def __init__(self,input_size,hidden_size, num_classes):\n",
        "    super(NeuralNet, self).__init__()\n",
        "    self.l1 = nn.Linear(input_size,hidden_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.l2 = nn.Linear(hidden_size,num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.l1(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.l2(out)\n",
        "    return out\n",
        "\n",
        "\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size, num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "n_total_steps = len(train_loader)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    images = images.reshape(-1, 28*28).to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "\n",
        "    output = model(images)\n",
        "    loss = criterion(output, labels)\n",
        "\n",
        "    break\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i+1)%100 ==0:\n",
        "      print(f'epoch {epoch+1} / {num_epochs,}, step {i+1}/n_total_steps, loss={loss.item()}')\n",
        "\n",
        "with  torch.no_grad():\n",
        "  n_correct = 0\n",
        "  n_samples = 0\n",
        "  for images, labels in test_loader:\n",
        "    images = images.reshape(-1, 28*28).to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(images)\n",
        "\n",
        "    _, predictions = torch.max(outputs, 1)\n",
        "    n_samples += labels.shape[0]\n",
        "\n",
        "    n_correct += (predictions == labels).sum().item()\n",
        "\n",
        "acc = 100 * n_correct /n_samples\n",
        "\n",
        "print(f'the accuracy ={acc}')\n"
      ],
      "metadata": {
        "id": "I1eO9AomOKJ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b660537e-f1bd-48ff-ad4c-ee86aca5015c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 1, 28, 28]) torch.Size([10])\n",
            "tensor([[-0.0099, -0.0978, -0.0463,  0.0589,  0.0425,  0.0449,  0.1402,  0.1256,\n",
            "          0.0971, -0.0808],\n",
            "        [-0.0331, -0.0021,  0.0302,  0.0998,  0.0624,  0.0144,  0.1366,  0.1243,\n",
            "          0.0984, -0.0720],\n",
            "        [-0.0980, -0.0761,  0.0141,  0.0963,  0.0957,  0.0433,  0.1104,  0.0246,\n",
            "          0.0662, -0.0732],\n",
            "        [ 0.0137, -0.0224,  0.0302,  0.0964,  0.0167,  0.0113,  0.0790,  0.1059,\n",
            "          0.0194, -0.0349],\n",
            "        [ 0.0030, -0.0069,  0.0391,  0.1161,  0.0524,  0.0820,  0.0766,  0.1242,\n",
            "          0.0241, -0.0501],\n",
            "        [-0.0265, -0.0231, -0.0190,  0.1906,  0.1462,  0.0065,  0.1055,  0.0545,\n",
            "          0.0766, -0.0361],\n",
            "        [-0.0497,  0.0727, -0.0337,  0.0834,  0.0862,  0.0301,  0.0306,  0.1579,\n",
            "          0.1119, -0.0308],\n",
            "        [ 0.0539, -0.1476,  0.0881,  0.0673,  0.1621,  0.0149, -0.0138,  0.0642,\n",
            "         -0.0039,  0.0330],\n",
            "        [-0.0612,  0.0070, -0.0138,  0.1080,  0.1365,  0.0022,  0.1404,  0.1423,\n",
            "          0.2057,  0.0514],\n",
            "        [ 0.0012,  0.0280,  0.0129,  0.0976,  0.0495,  0.0652,  0.0651,  0.0799,\n",
            "          0.1427, -0.0443]], grad_fn=<AddmmBackward0>)\n",
            "tensor([6, 7, 2, 1, 3, 7, 5, 4, 2, 7])\n",
            "tensor([[-0.0349, -0.1200, -0.0022,  0.0115,  0.2085,  0.0621,  0.1532,  0.1016,\n",
            "          0.1801, -0.0561],\n",
            "        [ 0.0464, -0.0020, -0.0822,  0.0651,  0.0617,  0.0185,  0.0477,  0.1536,\n",
            "          0.0548, -0.0497],\n",
            "        [ 0.0045,  0.0077,  0.0149,  0.1305,  0.0415, -0.0593,  0.0525,  0.2045,\n",
            "          0.0935,  0.0525],\n",
            "        [-0.0240, -0.1143,  0.0536,  0.0929,  0.0818, -0.0049,  0.0813,  0.0848,\n",
            "          0.0307, -0.0456],\n",
            "        [-0.0725,  0.0657, -0.0833,  0.0523,  0.0772, -0.0467,  0.0337,  0.1448,\n",
            "          0.1206, -0.0959],\n",
            "        [-0.0118,  0.0159,  0.0293,  0.0164,  0.0713, -0.0691,  0.1148,  0.1589,\n",
            "          0.1187,  0.0186],\n",
            "        [-0.0257, -0.0221,  0.0476,  0.1436,  0.1629,  0.0422,  0.1578,  0.0743,\n",
            "          0.0605, -0.0654],\n",
            "        [-0.0206, -0.0510, -0.0380,  0.0810,  0.1540,  0.0186, -0.0032,  0.0903,\n",
            "          0.1737, -0.0221],\n",
            "        [-0.0131,  0.0243,  0.0362,  0.2015,  0.1241,  0.0488,  0.1242,  0.0663,\n",
            "          0.0626, -0.0386],\n",
            "        [-0.0019, -0.1256,  0.0572,  0.0582,  0.1932, -0.0745,  0.0479,  0.0596,\n",
            "          0.0560,  0.0256]], grad_fn=<AddmmBackward0>)\n",
            "tensor([9, 4, 1, 4, 2, 3, 7, 9, 7, 4])\n",
            "the accuracy =12.68\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "input_size = 1024# 32X32 size\n",
        "hidden_size = 100\n",
        "num_classes = 10\n",
        "num_epochs = 2\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data',\n",
        "                                           train=True,\n",
        "                                           download=True,\n",
        "                                           transform=transforms.ToTensor())\n",
        "\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data',\n",
        "                                           train=False,\n",
        "                                           download=True,\n",
        "                                           transform=transforms.ToTensor())\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset= train_dataset,\n",
        "                                       batch_size=batch_size,\n",
        "                                       shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset= test_dataset,\n",
        "                                       batch_size=batch_size,\n",
        "                                       shuffle=True)\n",
        "\n",
        "examples= iter(train_loader)\n",
        "samples, labels = examples.__next__()\n",
        "print(samples.shape, labels.shape)\n",
        "print(labels[1])\n",
        "classes = ('plane','cat','bird','cat','deer','dog','frog','horse','ship','truck')\n",
        "\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ConvNet, self).__init__()\n",
        "    self.relu = nn.ReLU()\n",
        "    self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "    self.pool = nn.MaxPool2d(2,2)\n",
        "    self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "    self.fc1 = nn.Linear( 16*5*5, 120)\n",
        "    self.fc2 = nn.Linear( 120, 84)\n",
        "    self.fc3 = nn.Linear( 84, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    out = self.conv1(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.pool(out)\n",
        "    out = self.conv2(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.pool(out)\n",
        "    out = out.view(-1,16*5*5)\n",
        "    out = self.fc1(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.fc2(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.fc3(out)\n",
        "    return out\n",
        "\n",
        "\n",
        "\n",
        "model = ConvNet()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "n_total_steps = len(train_loader)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    output = model(images)\n",
        "    loss = criterion(output, labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i+1)%100 ==0:\n",
        "      print(f'epoch {epoch+1} / {num_epochs,}, step {i+1}/n_total_steps, loss={loss.item()}')\n",
        "\n",
        "with  torch.no_grad():\n",
        "  n_correct = 0\n",
        "  n_samples = 0\n",
        "  n_class_correct = [0 for i in range(10)]\n",
        "  n_class_samples = [0 for i in range(10)]\n",
        "\n",
        "  for images, labels in test_loader:\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(images)\n",
        "\n",
        "    _, predictions = torch.max(outputs, 1)\n",
        "    n_samples += labels.shape[0]\n",
        "\n",
        "    n_correct += (predictions == labels).sum().item()\n",
        "\n",
        "    for i in range(batch_size):\n",
        "      label= labels[i]\n",
        "      pred = predictions[i]\n",
        "      if (label == pred):\n",
        "        n_class_correct[label] +=1\n",
        "      n_class_samples[label] +=1\n",
        "\n",
        "acc = 100 * n_correct /n_samples\n",
        "print(f'the accuracy ={acc}')\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "  acc = 100*(n_class_correct[i]/n_class_samples[i])\n",
        "  print(f'the accuracy per class ={classes[i]}: {acc}')\n"
      ],
      "metadata": {
        "id": "qfypylzaXGS8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3a5e685-99b6-41bb-e73f-b8905857d053"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "torch.Size([100, 3, 32, 32]) torch.Size([100])\n",
            "tensor(8)\n",
            "epoch 1 / (2,), step 100/n_total_steps, loss=2.1070497035980225\n",
            "epoch 1 / (2,), step 200/n_total_steps, loss=1.8956571817398071\n",
            "epoch 1 / (2,), step 300/n_total_steps, loss=1.8732649087905884\n",
            "epoch 1 / (2,), step 400/n_total_steps, loss=1.5225754976272583\n",
            "epoch 1 / (2,), step 500/n_total_steps, loss=1.740366816520691\n",
            "epoch 2 / (2,), step 100/n_total_steps, loss=1.4622722864151\n",
            "epoch 2 / (2,), step 200/n_total_steps, loss=1.5676023960113525\n",
            "epoch 2 / (2,), step 300/n_total_steps, loss=1.2869360446929932\n",
            "epoch 2 / (2,), step 400/n_total_steps, loss=1.5908626317977905\n",
            "epoch 2 / (2,), step 500/n_total_steps, loss=1.3953689336776733\n",
            "the accuracy =46.69\n",
            "the accuracy per class =plane: 56.00000000000001\n",
            "the accuracy per class =cat: 70.5\n",
            "the accuracy per class =bird: 37.6\n",
            "the accuracy per class =cat: 21.9\n",
            "the accuracy per class =deer: 18.7\n",
            "the accuracy per class =dog: 48.1\n",
            "the accuracy per class =frog: 53.800000000000004\n",
            "the accuracy per class =horse: 63.0\n",
            "the accuracy per class =ship: 39.0\n",
            "the accuracy per class =truck: 58.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For Kaggel\n",
        "!pip install kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7Z5Yja-QSf8",
        "outputId": "87e031e6-cf4e-413e-b619-afde6704497e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.12)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_jySrNUVMlU",
        "outputId": "81e47341-d7c9-4f9a-fd18-a3d0c44cfc66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "403 - Forbidden - You must accept this competition's rules before you'll be able to download files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "input_size = 28 # 28X28 size\n",
        "sequence_length = 28\n",
        "num_layer = 2\n",
        "hidden_size = 256\n",
        "num_classes = 10\n",
        "num_epochs = 2\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "\n",
        "#Create RNN\n",
        "\n",
        "class RNN(nn.Module):\n",
        "  def __init__(self,input_size,hidden_size,num_layer,num_classes):\n",
        "    super(RNN, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layer\n",
        "    self.rnn = nn.RNN(input_size, hidden_size, num_layer, batch_first=True)\n",
        "    self.fc = nn.Linear(hidden_size*sequence_length, num_classes)\n",
        "\n",
        "  def forward(self,x):\n",
        "    h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "\n",
        "    out , _ = self.rnn(x, h0)\n",
        "    out = out.reshape(out.shape[0] , -1)\n",
        "    out = self.fc(out)\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                           train=True,\n",
        "                                           download=True,\n",
        "                                           transform=transforms.ToTensor())\n",
        "\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data',\n",
        "                                           train=False,\n",
        "                                           download=True,\n",
        "                                           transform=transforms.ToTensor())\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset= train_dataset,\n",
        "                                            batch_size=batch_size,\n",
        "                                            shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset= test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True)\n",
        "\n",
        "\n",
        "model =RNN(input_size,hidden_size,num_layer,num_classes)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "n_total_steps = len(train_loader)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    # images = images.reshape(-1, 28*28).to(device)\n",
        "    images = images.to(device).squeeze(1)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    output = model(images)\n",
        "    loss = criterion(output, labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i+1)%100 ==0:\n",
        "      print(f'epoch {epoch+1} / {num_epochs,}, step {i+1}/n_total_steps, loss={loss.item()}')\n",
        "\n",
        "with  torch.no_grad():\n",
        "  n_correct = 0\n",
        "  n_samples = 0\n",
        "  for images, labels in test_loader:\n",
        "    images = images.to(device).squeeze(1)\n",
        "    # images = images.reshape(-1, 28*28).to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(images)\n",
        "\n",
        "    _, predictions = torch.max(outputs, 1)\n",
        "    n_samples += labels.shape[0]\n",
        "\n",
        "    n_correct += (predictions == labels).sum().item()\n",
        "\n",
        "acc = 100 * n_correct /n_samples\n",
        "\n",
        "print(f'the accuracy ={acc}')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "E3LdgOXQAxtq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c35f9392-7249-48f0-bc2c-0e10cea66e78"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 / (2,), step 100/n_total_steps, loss=0.4723774492740631\n",
            "epoch 1 / (2,), step 200/n_total_steps, loss=0.3117121458053589\n",
            "epoch 1 / (2,), step 300/n_total_steps, loss=0.17260293662548065\n",
            "epoch 1 / (2,), step 400/n_total_steps, loss=0.08574503660202026\n",
            "epoch 1 / (2,), step 500/n_total_steps, loss=0.19376590847969055\n",
            "epoch 1 / (2,), step 600/n_total_steps, loss=0.13180750608444214\n",
            "epoch 1 / (2,), step 700/n_total_steps, loss=0.08959408104419708\n",
            "epoch 1 / (2,), step 800/n_total_steps, loss=0.2509249150753021\n",
            "epoch 1 / (2,), step 900/n_total_steps, loss=0.21614325046539307\n",
            "epoch 2 / (2,), step 100/n_total_steps, loss=0.23472826182842255\n",
            "epoch 2 / (2,), step 200/n_total_steps, loss=0.10334289073944092\n",
            "epoch 2 / (2,), step 300/n_total_steps, loss=0.030667368322610855\n",
            "epoch 2 / (2,), step 400/n_total_steps, loss=0.09823117405176163\n",
            "epoch 2 / (2,), step 500/n_total_steps, loss=0.06943372637033463\n",
            "epoch 2 / (2,), step 600/n_total_steps, loss=0.14066016674041748\n",
            "epoch 2 / (2,), step 700/n_total_steps, loss=0.15530987083911896\n",
            "epoch 2 / (2,), step 800/n_total_steps, loss=0.09062447398900986\n",
            "epoch 2 / (2,), step 900/n_total_steps, loss=0.32817375659942627\n",
            "the accuracy =96.14\n"
          ]
        }
      ]
    }
  ]
}